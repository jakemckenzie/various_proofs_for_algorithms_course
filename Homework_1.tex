
\documentclass[12pt]{article}
\usepackage{amsmath,amssymb,amsthm}
\begin{document}
\title{TCSS 343 - Assignment 1}
\maketitle


\section{2.1 Understand}

Prove the theorem below. 
Use a \textbf{direct proof} to find constants that satisfy the definition of \begin{math}\Theta(n^2)\end{math} or use the \textbf{limit test}.  
Make sure your proof is complete, concise, clear and precise.
\\\\\textbf{Theorem 1.} 
\begin{math}n^5-64n^3-n^2 \epsilon \Theta(n^5)\end{math}
\\\\For the first theorem a limit test was used to ensure that polynomial given was \begin{math}\Theta(n^5)\end{math}. For most limits of 
this nature it is best to factor the polynomial, this usually results in a short elegant solution. 
\[ \lim_{n \to \infty}  \frac{n^5-64n^3-n^2}{n^5} = \lim_{n \to \infty} \frac{n^5}{n^5}\Bigg(\frac{1-\frac{64}{n^2}-\frac{1}{n^3}}{1}\Bigg) = \lim_{n \to \infty} 1\Bigg(\frac{1-0-0}{1}\Bigg) = \lim_{n \to \infty} 1 = 1\]
\\Since the limit converged to 1, a positive constant value, we may say that theorem 1 is indeed true.\\\\
\noindent Prove Gauss’s sum using induction on \begin{math}n\end{math}. Make sure to include a base case for \begin{math} n = 1\end{math} and an inductive hypothesis and an inductive step for \begin{math}n > 1\end{math}.\\

\noindent \textbf{Theorem 2.}
\begin{math}P(n):\sum\limits_{i = 1}^{n} i = \frac{n(n + 1)}{2} \forall n \epsilon \mathbb{Z}_+  \end{math}\\
\\\\For this proof I used the fundamental theorem of algebra to help assist me. I hope that the steps are clear.\\
\begin{enumerate}
\item Base Case:\\
\[P(1):\sum\limits_{i = 1}^{1} i = 1  = \frac{1(1+1)}{2} = \frac{2}{2} = 1\]
\item Inductive Hypothesis:
\[P(k):\sum\limits_{i = 1}^{k} i = \frac{k(k + 1)}{2} \forall k \epsilon \mathbb{Z}_+\]
\item Inductive Step:

\begin{align*}
P(k+1):\sum\limits_{i = 1}^{k+1} i &= \frac{(k + 1)(k+2)}{2} \forall k \epsilon \mathbb{Z}_+\\
\sum\limits_{i = 1}^{k} i + (k + 1)&= \frac{(k + 1)(k+2)}{2}\\
\intertext{Preparation for introduction of inductive hypothesis.}\\
\frac{k(k+1)}{2} + (k+1)&= \frac{(k + 1)(k+2)}{2}\\
\intertext{Introduction of the iductive hypothesis.}\\
\frac{k(k+1)}{2} + \frac{2(k+1)}{2}&= \frac{(k + 1)(k+2)}{2}\\
\frac{k(k+1)+ 2(k+1)}{2}&= \frac{(k + 1)(k+2)}{2}\\
\frac{(k + 1)(k+2)}{2}&= \frac{(k + 1)(k+2)}{2}\\
&\hspace{0.3cm}\qedsymbol
\end{align*}
\end{enumerate}
\noindent Prove Gauss’s sum using induction on \begin{math}n\end{math}. Make sure to include a base case for \begin{math} n = 1\end{math} and an inductive hypothesis and an inductive step for \begin{math}n > 1\end{math}.\\\\
\noindent \textbf{Theorem 3.}
\begin{math}P(n):\sum\limits_{i = 1}^{n} i^5 = \big(\frac{n(n + 1)}{2}\big)^2\frac{2n^2+2n-1}{3} \forall n \epsilon \mathbb{Z}_+  \end{math}
\\\\For this proof I used the fundamental theorem of algebra to help assist me. The last three steps of the inductive step to ensure \begin{math}P(k+1)\end{math} step I obtained those steps by expanding the right hand side and ensuring that each polynomial on the left hand side matched the right hand side. Those were included on the left hand side in reverse to ensure continuity.\\
\begin{enumerate}

\item Base Case:\\
\begin{align*}
P(1):\sum\limits_{i = 1}^{1} i^5 &= \big(\frac{1(1 + 1)}{2}\big)^2\frac{2(1)^2+2(1)-1}{3}\\
1^5 &= \big(\frac{1(2)}{2}\big)^2\frac{3}{3}\\
1 &= 1
\end{align*}

\item Inductive Hypothesis:
\begin{align*}
&P(k):\sum\limits_{i = 1}^{k} i^5 = \big(\frac{k(k + 1)}{2}\big)^2\frac{2k^2+2k-1}{3} \forall k \epsilon \mathbb{Z}_+
\end{align*}
\item Inductive Step:
\begin{align*}
P(k+1):\sum\limits_{i = 1}^{k+1} i^5 = \big(\frac{(k+1)(k + 1 + 1)}{2}\big)^2\frac{2(k+1)^2+2(k+1)-1}{3} \forall k \epsilon \mathbb{Z}_+ \\
\sum\limits_{i = 1}^{k} i^5 + (k + 1)^5 = \big(\frac{(k+1)(k + 2)}{2}\big)^2\frac{2k^2+5k+2}{3} \\
\intertext{Preparation of the inductive hypothesis.}
\bigg(\frac{k(k + 1)}{2}\bigg)^2\frac{2k^2+2k-1}{3} + (k + 1)^5 &=\\
\intertext{Introduction of the inductive hypothesis.}
\bigg(\frac{1}{12}\bigg)[k^2(k+1)^2(2k^2+2k-1)+12(k+1)^5]&= \\
\bigg(\frac{1}{12}\bigg)[(k^4+2k^3+k^2)(2k^2+2k-1)+12(k+1)^5]&=\\
\intertext{My technique for proofs such as these is expansion then contraction. It is typically much easier to see where to go with a polynomial once you've fully expanded all terms.}\\
\bigg(\frac{1}{12}\bigg)(2k^6+6k^5+5k^4-k^2+12k^5+60k^4+120k^3+120k^2+60k+12))&=\\
\bigg(\frac{1}{12}\bigg)(2k^6+18k^5+65k^4+120k^3+119k^2+60k+12))&=\\
\bigg(\frac{1}{12}\bigg)(k^4+6k^3+13k^2+12k+4)(2k^2+6k+3)&=\\
\bigg(\frac{1}{12}\bigg)(k^2+3k+2)^2(2k^2+6k+3)&=\\
\big(\frac{(k+1)(k + 2)}{2}\big)^2\frac{2k^2+6k+3}{3}&=\\
\intertext{The prior three steps were obtained by fully expanding the LHS to make it match the fully expanded polynomial four lines above. By the fundamental theorem of algebra, I knew I obtained the desired results. Those steps were included in reverse on the LHS for the readers benefit of readability.}
&\hspace{0.3cm}\qedsymbol
\end{align*}
\end{enumerate}
Prove by induction that for all natural numbers \begin{math}x\end{math} and \begin{math}n\end{math}, \begin{math}x^n - 1\end{math} is divisible by \begin{math}x - 1\end{math}.\\\\
\noindent For this proof I decided to show that \begin{math}x - 1\mid x^n - 1\end{math} which is equivant \begin{math}P(x,n):x^n - 1 = k(x - 1) ; k \epsilon \mathbb{Z}_+ \end{math} where k is any integer multiple.\\\\ 
\begin{enumerate}
\item Base Case:\\
\[P(1):x^1 - 1 = 0 = k(x - 1); true if k = 1\]\\
\item Inductive Hypothesis:
\[P(m):a^m - 1 = k(a - 1) ; \forall a,m,k \epsilon \mathbb{Z}_+\]
\item Inductive Step:\\
\begin{align*}
P(m+1):a^{m+1} - 1 &= k(a - 1) ; \forall a,m,j,k \epsilon \mathbb{Z}_+\\
a^{m+1} - 1 + a - a &= k(a - 1)\\
\intertext{By adding and subtracting a to the LHS we do not change the equation at all.}\\
(a^{m+1} - a) + (a - 1) &= k(a - 1)\\
\intertext{Grouping of terms.}\\
a(a^{m} - 1) + (a - 1) &= k(a - 1)\\
\intertext{Preparation for introduction of the inductive hypothesis.}\\
a*j(a - 1) + (a - 1) &= k(a - 1)\\
\intertext{Introduction of the inductive hypothesis.}\\
(a - 1)(a*j + 1) &= k(a - 1)\\
\intertext{Factoring to show that LHS is divisible by (a - 1)}\\
&\hspace{0.3cm}\qedsymbol
\end{align*}
\end{enumerate}
It is important to note that the proof above need not have j and k above that are equal to each other for the proof to work. In fact, for the proof to be satisfied, the two integers need to be not equal for it to work.\\\\
Prove by induction that \begin{math}x^n - y^n\end{math} is divisible by \begin{math}x - y\end{math} for all natural numbers x, y (with \begin{math}x \not = y\end{math}), and n.\\\\
\noindent Show \begin{math}\forall x,y,n,k \epsilon \mathbb{Z}_+ ; P(n):(x^n-y^n) = k * (x-y)\end{math} where k is any integer multiple.
\begin{enumerate}
\item Base Case:\\
\[P(1): x^1 - y^1   = x - y = k * (x - y)\]\\
\item Inductive Hypothesis:
\[P(j):(a^j - b^j) = k(a - b); \forall a,b,j,k \epsilon \mathbb{Z}_+\]
\item Inductive Step:\\
\begin{align*}
P(j+1):(a^{j+1} - b^{j+1}) &= k(a-b); \forall a,b,j,k,g \epsilon \mathbb{Z}_+ \intertext{where k and g may be any integer that satisfies the relationship.}\\
a^{j+1} - b^{j+1} + b*a^j - b*a^j &= k(a-b)\\
\intertext{Adding these two terms does not change anything and makes it more easily manipulatable.}\\
a^j(a-b) + b(a^j-b^j) &= k(a-b)\\
a^j(a-b) + g(a - b) &= k(a-b)\\
\intertext{Introduction of the inductive hypothesis. Clearly all terms are divisible by (a - b). Like with the previous theorem, g and k must not be equal for this proof to be true.}\\
&\hspace{0.3cm}\qedsymbol
\end{align*}
\end{enumerate}
Prove the following theorem using the definition of \begin{math} \Omega (f (n))\end{math} and \begin{math}O(f (n))\end{math} , or else the limit test.\\\\
\noindent \textbf{Theorem 4.} Let \begin{math}d \geq 2\end{math} be an integer. Then \begin{math}\sqrt[^d]{n} \epsilon \Omega (\sqrt[^{2d}]{n})\end{math} and \begin{math}(\ln {n}^d) \epsilon O(\sqrt{n})\end{math}\\\\
\begin{align}
\lim_{n\to\infty} \frac{n^{\frac{1}{d}}}{n^{\frac{1}{2d}}} &= \lim_{n\to\infty} n^{\frac{1}{d}} n^{\frac{-1}{2d}}\\
&= \lim_{n\to\infty} n^{\frac{1}{d}-\frac{1}{2d}}\\
&= \lim_{n\to\infty} n^{\frac{1}{2d}} \rightarrow \infty
\end{align}\\
Use the fact that for any \begin{math} n  \geq 1\end{math} by the Cauchy-Sqwarz inequality\
\[(\ln{n})^d = (\int_{1}^{n} \frac{dx}{x})^d \leq (\int_{1}^{n} dx \int_{1}^{n} \frac{dx}{x^2})^{\frac{d}{2}} = ((n-1)(1-\frac{1}{n}))^{\frac{d}{2}} = (n + \frac{1}{n} - 2)^{\frac{d}{2}}\]\\
Producing an important result for intuition when considering the smallest value of d:
\[(\ln{n})^d \leq n \leq (n + \frac{1}{n} - 2)^{\frac{d}{2}}\]
Using the result of prior limit test and immediate results above (since \begin{math}d \geq 2\end{math}), we cannot immediately state that the limit approaches 0.
\[\lim_{n\to\infty} \frac{(\ln{n})^d}{\sqrt{n}} =\lim_{n\to\infty} \frac{(2\ln{\sqrt{n}})^d}{\sqrt{n}} \rightarrow 0\]
From the result above and just prior, I can say with some certainty that no matter how large d is, it is a finite value. From consulting concrete mathematics, pages 426 and 427, that applying a logarithm to a sqrt will grow far slower than any square root, if it's power is finite. 
\section{2.1 Understand}
Place these functions in order from slowest asymptotic growth to fastest asymptotic growth. You will want to simplify them algebraically before comparing them. Give a short justification (a proof is not necessary) of how you came to this ordering.\\\\\
According to Donald Knuth, in Concrete Mathematics page 426 and 427, hierarchy and asymptotics of functions was introduced by Paul du Bois-Reymond in 1871 with the following definition:\\\\ 
\[f(n) < g(n) \Longleftrightarrow \lim_{n\to\infty} \frac{f(n)}{g(n)} = 0\]
Knuth continues on to give a what he calls,"asymptotic pecking order"(where \begin{math}0 < \epsilon < 1 < c\end{math}) which I used to solve this problem:
\[1 < \log{\log{n}} < \log{n} < n^{\epsilon} < n^c < n^{log{n}} < c^n < n^n < c^{c^{n}}\]
Using this pecking order, I made educated guesses as to which functions grew slower than others, then used Mathematica to check these guesses.
\begin{enumerate}
\item \begin{math}f_7(n) = \log{\log{n-1}}\end{math}\\
The above function is clearly smaller than the function below it. Applying a logarithm to another logarithm significantly slows down the asymptotic growth.
\item \begin{math}f_6(n) = \log{n-1}\end{math}\\
The above function is clearly smaller than the function below it once a simplification is appliwed to the below function. n dominates any logarithm.
\item \begin{math}f_5(n) = \log{n^n} = n \log{n}\end{math}\\
The degree of the polynomial above is smaller than that below.
\item \begin{math}f_3(n) = 4^{\log{n}} = n^2 \end{math}\\
The degree of the polynomial above is smaller than that below.
\item \begin{math}f_2(n) = (\frac{n}{\log{n}})^3=n^3(\frac{1}{\log{n}})^3\end{math}\\
The degree of the polynomial above is same as that below but the function above is has a division of logarithm which slows it down.
\item \begin{math}f_0(n) = n^3 + n^2 + n + 1\end{math}\\
No simplication of the function below that I know of can be applied but by looking at Knuth's pecking order I can see that any function of the form \begin{math}c^n\end{math} will be greater than \begin{math}n^c\end{math}.
\item \begin{math}f_8(n) = 100^{\sqrt{n}}\end{math}\\
By consulting concrete mathematics, when you have two different exponetials you need to compare the powers of the function inside the power. Since \begin{math}\sqrt{n} < n\end{math} the function above grows slower than that below.
\item \begin{math}f_4(n) = 9^{\frac{n}{2}} = 3^{n}\end{math}\\
Since \begin{math}n < 2n\end{math} the function above grows slower than that below.
\item \begin{math}f_1(n) = 3^{2n}\end{math}\\
Since all other cases have been exhausted this function above should grow the fastest.\\\\
\end{enumerate}
With use of mathematica and the definition Knuth provided (\begin{math}f(n) < g(n) \Longleftrightarrow \lim_{n\to\infty} \frac{f(n)}{g(n)} = 0\end{math}), I obtained the following results, where the row corresponds the \begin{math}f_i(n)\end{math} and  the column corresponds to \begin{math}g_j(n)\end{math}:\\
\[
    \begin{bmatrix}
        1 & 0 & \infty & \infty & 0 & \infty & \infty & \infty & 0\\
        \infty & 1 & \infty & \infty & \infty & \infty & \infty & \infty & \infty\\
        0 & 0 & 1 & \infty & 0 & \infty & \infty & \infty & 0\\
        0 & 0 & 0 & 1 & 0 & \infty & \infty & \infty & 0\\
        \infty & 0 & \infty & \infty & 1 & \infty & \infty & \infty & \infty\\
        0 & 0 & 0 & 0 & 0 & 1 & \infty & \infty & 0\\
        0 & 0 & 0 & 0 & 0 & 0 & 1 & \infty & 0\\
        0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0\\
        \infty & 0 & \infty & \infty & 0 & \infty & \infty & \infty & 1
    \end{bmatrix}
\]
The rows with the most zeros or likewise the column with the most infinities in them should match to the ordering of what I obtained, which we see that it does. In the workplace and in the future I will make heavy use of technology to reduce errors and introduce beck practices, so I felt like it was important to show this step.
\end{document}